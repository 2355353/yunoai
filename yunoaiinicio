import pyttsx3
import speech_recognition as sr
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from gtts import gTTS
import pygame
from PIL import Image, ImageDraw, ImageFont
import transformers
from transformers import pipeline
import re

nltk.download('punkt')
nltk.download('stopwords')

def initialize_engine():
    engine = pyttsx3.init()
    voices = engine.getProperty('voices')
    engine.setProperty('voice', voices[0].id)  # Seleccionar una voz masculina
    return engine

def text_to_speech(text, engine):
    engine.say(text)
    engine.runAndWait()

def speech_to_text():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Escuchando...")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)
    try:
        query = recognizer.recognize_google(audio, language='es-ES')
        print(f"Usuario: {query}")
        return query
    except sr.UnknownValueError:
        print("Lo siento, no he podido entender lo que has dicho.")
        return ""
    except sr.RequestError:
        print("Lo siento, ha ocurrido un error al intentar procesar la solicitud.")
        return ""

def generate_image_from_text(text):
    img = Image.new('RGB', (800, 600), color='white')
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype("arial.ttf", 36)
    draw.text((10, 10), text, fill='black', font=font)
    img.save('output_image.png')
    img.show()

def process_query(query):
    # Procesar la consulta utilizando múltiples modelos de IA
    nlp = pipeline("zero-shot-classification")
    candidate_labels = ["respuesta", "imagen"]
    result = nlp(query, candidate_labels)
    labels = result['labels']
    scores = result['scores']

    # Determinar la acción basada en los resultados del modelo
    max_score_index = scores.index(max(scores))
    action = labels[max_score_index]

    if action == 'respuesta':
        # Realizar un análisis sintáctico de la consulta y extraer entidades relevantes
        entities = extract_entities(query)
        # Generar una respuesta contextualizada utilizando las entidades extraídas
        response = generate_response(entities)
    elif action == 'imagen':
        # Generar una imagen basada en la consulta del usuario
        response = "Esta es una imagen generada a partir de tu consulta."
        generate_image_from_text(query)
    else:
        response = "Lo siento, no puedo responder a esa pregunta en este momento."

    return response

def extract_entities(query):
    # Realizar un análisis sintáctico de la consulta y extraer entidades relevantes
    tokens = word_tokenize(query)
    stop_words = set(stopwords.words('spanish'))
    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]
    tagged = nltk.pos_tag(filtered_tokens)
    named_entities = nltk.ne_chunk(tagged)
    entities = []
    for entity in named_entities:
        if isinstance(entity, nltk.tree.Tree):
            entities.append(" ".join([word for word, _ in entity]))
    return entities

def generate_response(entities):
    # Generar una respuesta contextualizada utilizando las entidades extraídas
    if entities:
        response = f"Entiendo que estás interesado en {' y '.join(entities)}. Aquí tienes una respuesta adecuada."
    else:
        response = "No puedo identificar entidades relevantes en tu consulta. Por favor, sé más específico."
    return response

def assistant_personal():
    engine = initialize_engine()
    print("Bienvenido al Asistente Personal. Puedes hablar o escribir tus preguntas.")

    while True:
        # Escuchar la consulta del usuario
        query = speech_to_text()

        if not query:
            continue

        if 'salir' in query.lower():
            print("¡Adiós! Hasta luego.")
            break

        # Procesar la consulta y generar una respuesta
        response = process_query(query)

        # Convertir la respuesta a voz y reproducirla
        text_to_speech(response, engine)

        print("Respuesta generada y presentada.")
        print("")

# Ejecutar el asistente personal
assistant_personal()
